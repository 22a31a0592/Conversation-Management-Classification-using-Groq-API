{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xeL9xjd7ugw",
        "outputId": "a9ef80c5-289e-4d4a-a00d-7583d463ad5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.1\n"
          ]
        }
      ],
      "source": [
        "!pip install groq\n",
        "import os\n",
        "from groq import Groq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass(\"Enter your Groq API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obp4VITVxXkv",
        "outputId": "8f61a3a3-481c-4cc4-96d7-c1c9dbf8c7d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = Groq(api_key=api_key)\n"
      ],
      "metadata": {
        "id": "JKBfT8eR9stf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "\n",
        "def add_message(role, content):\n",
        "    history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "def truncate_by_turns(n):\n",
        "    return history[-n:]\n",
        "\n",
        "def truncate_by_length(max_chars):\n",
        "    total, result = 0, []\n",
        "    for msg in reversed(history):\n",
        "        total += len(msg[\"content\"])\n",
        "        if total > max_chars:\n",
        "            break\n",
        "        result.insert(0, msg)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "0GlJSZ7P93pJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_history(cur_history):\n",
        "    summary_prompt = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Summarize the following conversation in 5 sentences.\"},\n",
        "        {\"role\": \"user\", \"content\": \"\\n\".join([m[\"role\"] + \": \" + m[\"content\"] for m in cur_history])}\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "        messages=summary_prompt,\n",
        "        max_tokens=300,\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "hApF4MoMFXBT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def periodic_summary(k=3):\n",
        "    if len(history) % k == 0 and len(history) > 0:\n",
        "        summary = summarize_history(history)\n",
        "        history.clear()\n",
        "        history.append({\"role\": \"system\", \"content\": \"Conversation summary: \" + summary})\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2gr1y6Gx-C0L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.clear()\n",
        "\n",
        "add_message(\"user\", \"Can you help me prepare for a data analyst interview?\")\n",
        "add_message(\"assistant\", \"Sure! What topics should we focus on?\")\n",
        "add_message(\"user\", \"I want to practice SQL and Python questions.\")\n",
        "add_message(\"assistant\", \"Great! For SQL, do you want SELECT queries or joins?\")\n",
        "add_message(\"user\", \"Both would be helpful.\")\n",
        "add_message(\"assistant\", \"Okay, I'll prepare some examples.\")\n",
        "print(\"Last 2 turns:\", truncate_by_turns(2))\n",
        "print(\"Truncated to 40 chars:\", truncate_by_length(40))\n",
        "periodic_summary(k=3)\n",
        "print(\"Current: \", history)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCeUR3BF-JwO",
        "outputId": "91bc4396-a6be-4d14-a7c9-0d7aa6bc7413"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 2 turns: [{'role': 'user', 'content': 'Both would be helpful.'}, {'role': 'assistant', 'content': \"Okay, I'll prepare some examples.\"}]\n",
            "Truncated to 40 chars: [{'role': 'assistant', 'content': \"Okay, I'll prepare some examples.\"}]\n",
            "Current:  [{'role': 'system', 'content': 'Conversation summary: Here is a summary of the conversation in 5 sentences:\\n\\nA user asked for help preparing for a data analyst interview. The user expressed interest in practicing SQL and Python questions. The assistant offered to help and asked which SQL topics to focus on. The user requested practice with both SELECT queries and joins in SQL. The assistant agreed to prepare examples to help the user practice.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"name\": {\"type\": \"string\"},\n",
        "    \"email\": {\"type\": \"string\"},\n",
        "    \"phone\": {\"type\": \"string\"},\n",
        "    \"location\": {\"type\": \"string\"},\n",
        "    \"age\": {\n",
        "  \"anyOf\": [\n",
        "    {\"type\": \"integer\"},\n",
        "    {\"type\": \"string\", \"pattern\": \"^[0-9]+$\"}\n",
        "  ]\n",
        "}\n",
        "\n",
        "  },\n",
        "  \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "}\n",
        "\n",
        "tools = [\n",
        "  {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "      \"name\": \"extract_user_info\",\n",
        "      \"description\": \"Extracts user info from chat.\",\n",
        "      \"parameters\": schema\n",
        "    }\n",
        "  }\n",
        "]\n"
      ],
      "metadata": {
        "id": "qKFP2x37a08c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_user_info(chat_content):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Extract user info from the following chat.\"},\n",
        "        {\"role\": \"user\", \"content\": chat_content}\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        max_tokens=300,\n",
        "    )\n",
        "    arguments = response.choices[0].message.tool_calls[0].function.arguments\n",
        "\n",
        "    import json\n",
        "    info = json.loads(arguments)\n",
        "    if 'age' in info and isinstance(info['age'], str):\n",
        "        try:\n",
        "            info['age'] = int(info['age'])\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    desired_order = [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "    ordered_info = {k: info[k] for k in desired_order if k in info}\n",
        "\n",
        "    return ordered_info\n"
      ],
      "metadata": {
        "id": "yqp2j1PXdV18"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\n",
        "    \"Hi, I'm Alice. My email is alice@example.com, phone is 1234567890. I live in Mumbai, and I'm 23.\",\n",
        "    \"Hey, Bob here. Contact: bob@mail.com, +911234567890, Delhi, 32 years old.\",\n",
        "    \"Carol's details: carol@email.com, 9988776655, Bangalore, 27.\",\n",
        "]\n",
        "for s in samples:\n",
        "    print(classify_user_info(s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTOPjcp5bJTi",
        "outputId": "3ba9690c-9158-4526-9c88-604f6f424640"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Alice', 'email': 'alice@example.com', 'phone': '1234567890', 'location': 'Mumbai', 'age': 23}\n",
            "{'name': 'Bob', 'email': 'bob@mail.com', 'phone': '+911234567890', 'location': 'Delhi', 'age': 32}\n",
            "{'name': 'Carol', 'email': 'carol@email.com', 'phone': '9988776655', 'location': 'Bangalore', 'age': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPU6FZaGtboH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}